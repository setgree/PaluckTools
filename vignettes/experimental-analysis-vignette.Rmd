---
title: "Analyzing experimental data"
output:
  rmarkdown::html_vignette:
    number_sections: true
    fig_width: 7
    fig_height: 7
vignette: >
  %\VignetteIndexEntry{Analyzing experimental data}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

This vignette demonstrates tools for analyzing experimental data. While the previous vignettes focused on meta-analysis, this one covers the experimental analysis workflow using functions designed to streamline common tasks in social psychology research.

When you analyze experimental data, you often need to:

- Run many regression specifications (different dependent variables, different sets of controls, different subsamples)
- Account for clustering in your standard errors (students within schools, voters within precincts)
- Extract and report treatment effects efficiently

BLPlabtools provides two main categories of functions to help with these tasks:

1. **`tidy_lm`** for running multiple regression specifications efficiently
2. **`robust_se`** for cluster-robust standard errors

This vignette walks through each of these tools using realistic simulated data from a growth mindset intervention study. For information on creating publication-ready tables from your results, see the "Creating publication-ready tables" vignette.

# Example data: Growth mindset intervention

For realistic examples, we'll create a simulated dataset from a typical social psychology experiment. Imagine a study testing whether a growth mindset intervention improves student outcomes across 20 schools (100 students per school).

```{r simulate_data}
library(BLPlabtools)
library(dplyr)

set.seed(123)  # For reproducibility

# Simulate experimental data
n_schools <- 20
n_per_school <- 100
n_total <- n_schools * n_per_school

experiment_data <- data.frame(
  student_id = 1:n_total,
  school_id = rep(1:n_schools, each = n_per_school),
  # Treatment assignment (randomized within schools)
  treatment = rep(c(rep(0, n_per_school/2), rep(1, n_per_school/2)), n_schools),
  # Baseline covariates
  baseline_score = rnorm(n_total, mean = 70, sd = 15),
  gender = sample(c("female", "male"), n_total, replace = TRUE),
  # Outcomes (treatment effect = +5 points on average)
  test_score = 70 + 5*rep(c(rep(0, n_per_school/2), rep(1, n_per_school/2)), n_schools) +
               rnorm(n_total, sd = 12),
  attendance = 0.85 + 0.03*rep(c(rep(0, n_per_school/2), rep(1, n_per_school/2)), n_schools) +
               rnorm(n_total, sd = 0.1),
  attitudes = 3.5 + 0.3*rep(c(rep(0, n_per_school/2), rep(1, n_per_school/2)), n_schools) +
              rnorm(n_total, sd = 0.8)
) |>
  mutate(
    treatment = factor(treatment, levels = c(0, 1), labels = c("Control", "Treatment")),
    gender = factor(gender)
  )

# Preview the data structure
head(experiment_data)
```

This dataset has:
- **2,000 students** across **20 schools** (clustered data)
- **Treatment variable**: Growth mindset intervention (Control vs Treatment)
- **Baseline covariate**: prior test scores, gender
- **Outcomes**: test scores, attendance rate, attitude scale (1-5)

## What your experimental data should look like

For experimental analysis with `tidy_lm` and `robust_se`, your data should be in "long" format with one row per observation (student, participant, unit). Here's what you need:

**Essential columns:**

- **ID variables**: Unique identifier for each observation (e.g., `student_id`)
- **Clustering variable**: If data are clustered (e.g., `school_id`, `site_id`, `pair_id`)
- **Treatment variable**: Binary or factor variable indicating treatment assignment (e.g., `treatment`)
- **Outcome variables**: Numeric variables you want to analyze (e.g., `test_score`, `attendance`, `attitudes`)

**Recommended columns:**

- **Baseline covariates**: Pre-treatment variables for precision (e.g., `baseline_score`, `gender`, `age`)
- **Moderators**: Variables for subgroup analysis (e.g., `gender`, `school_type`)

The `tidy_lm` function is designed to work with **tidy data** where:
- Each row is an observation
- Each column is a variable
- Each cell contains a single value

This is the standard format for data analysis in R. If your data are in wide format (e.g., separate columns for pretest and posttest), you'll need to reshape them using `tidyr::pivot_longer()` or similar tools.

**A note on clustering**: If your experimental units are nested (students within schools, voters within precincts), you should account for this by specifying the `clusters` parameter in `tidy_lm` or using `robust_se` directly. This adjusts standard errors to account for within-cluster correlation and prevents false precision in your estimates.

# Running multiple regressions with `tidy_lm`

When analyzing experimental data, you often need to run many regression specifications: different dependent variables, different sets of controls, different subsamples. The `tidy_lm` function streamlines this process by allowing you to specify multiple models at once and returning the results in a tidy data frame format.

## Basic usage

Test whether the treatment affects test scores:

```{r basic_tidy_lm}
# Simple treatment effect
results <- tidy_lm(
  data = experiment_data,
  dv = "test_score",
  terms = "treatment",
  treatment = "treatment"
)

# View treatment coefficient
results |> select(dv, treatmentTreatment_coef, treatmentTreatment_p)
```

The output is a tidy data frame where each row represents one regression model. The `treatment` parameter extracts coefficients automatically.

## Multiple dependent variables

Test treatment effects across all outcomes simultaneously:

```{r multiple_dvs}
# Test treatment on test scores, attendance, and attitudes
multi_outcome <- tidy_lm(
  data = experiment_data,
  dv = c("test_score", "attendance", "attitudes"),
  terms = "treatment",
  treatment = "treatment"
)

# View treatment effects across all outcomes
multi_outcome |> select(dv, treatmentTreatment_coef, treatmentTreatment_p)
```

## Different regression styles

Control for baseline covariates in different ways:

```{r regression_styles}
# "bivariate": treatment only
bivariate <- tidy_lm(
  data = experiment_data,
  dv = "test_score",
  terms = "treatment",
  style = "bivariate"
)

# "incremental": progressively add controls
incremental <- tidy_lm(
  data = experiment_data,
  dv = "test_score",
  terms = c("treatment", "baseline_score", "gender"),
  treatment = "treatment",
  style = "incremental"
)

# "default": all terms together
full_model <- tidy_lm(
  data = experiment_data,
  dv = "test_score",
  terms = c("treatment", "baseline_score", "gender"),
  treatment = "treatment",
  style = "default"
)

cat("Bivariate:", nrow(bivariate), "model\n")
cat("Incremental:", nrow(incremental), "models (adds controls one at a time)\n")
cat("Default:", nrow(full_model), "model (all controls together)\n")
```

## Real-world workflow: Multiple outcomes with controls

A typical analysis tests treatment effects on multiple outcomes, with and without controls:

```{r typical_workflow}
# Analyze all outcomes with progressive controls
full_analysis <- tidy_lm(
  data = experiment_data,
  dv = c("test_score", "attendance", "attitudes"),
  terms = c("treatment", "baseline_score", "gender"),
  treatment = "treatment",
  style = "incremental"
)

# Extract treatment effects across all specifications
full_analysis |>
  select(model_number, dv, treatmentTreatment_coef,
         treatmentTreatment_se, treatmentTreatment_p) |>
  mutate(significant = treatmentTreatment_p < 0.05)
```

# Cluster-robust standard errors

Our students are clustered within schools, so we need cluster-robust standard errors to account for within-school correlation. Why does this matter? When observations are clustered (students within schools, voters within precincts), the usual assumption that observations are independent is violated. Students in the same school might be more similar to each other than to students in other schools, which means the standard errors from ordinary regression will be too small, leading to overconfident conclusions.

## Using `robust_se`

```{r robust_se}
# Basic regression (ignores clustering)
model <- lm(test_score ~ treatment + baseline_score, data = experiment_data)

# Get cluster-robust SEs (clustering by school)
robust_results <- robust_se(model, cluster = experiment_data$school_id)

# robust_results is a list with:
# [[1]]: variance-covariance matrix
# [[2]]: coefficient test with robust SEs

robust_results[[2]]
```

Notice the standard errors are typically larger than classical SEs, reflecting within-cluster correlation.

## Incorporating clusters into `tidy_lm`

For multiple specifications with clustering, use `tidy_lm` directly:

```{r tidy_lm_clusters}
# Run multiple specifications with clustering
clustered_models <- tidy_lm(
  data = experiment_data,
  dv = c("test_score", "attendance"),
  terms = c("treatment", "baseline_score", "gender"),
  treatment = "treatment",
  clusters = "school_id",
  style = "incremental"
)

# Extract treatment effects (now with cluster-robust SEs)
clustered_models |>
  select(dv, model_number, treatmentTreatment_coef, treatmentTreatment_se, treatmentTreatment_p)
```

# Preparing results for publication

Once you've run your analyses, you'll want to create publication-ready tables. The `star_ready()` function prepares `tidy_lm` output for use with the `stargazer` package:

```{r star_ready_demo, eval=FALSE}
# First, run your models
models <- tidy_lm(
  data = experiment_data,
  dv = "test_score",
  terms = c("treatment", "baseline_score"),
  style = "incremental",
  clusters = "school_id"
)

# Prepare for stargazer
ready_for_table <- star_ready(models, data = experiment_data)

# Now use with stargazer
library(stargazer)
stargazer(ready_for_table, type = "latex")
```

For detailed information on formatting tables (adding footnotes, adjusting p-value display, resizing, etc.), see the "Creating publication-ready tables" vignette.

# Key takeaways

**For running regressions:**
- Use `tidy_lm` when you need to run many specifications
- Specify `treatment` to extract coefficients you care about
- Use `clusters` for cluster-robust standard errors
- Choose `style` based on your needs (bivariate, incremental, default)

**For preparing tables:**
- `star_ready` bridges `tidy_lm` output to `stargazer`
- See the "Creating publication-ready tables" vignette for formatting options

**Best practices:**
- Always cluster standard errors when you have grouped data
- Run robustness checks with different specifications
- Document your analytical choices clearly

For more examples, see the function documentation with `?tidy_lm`, `?robust_se`, or `?star_ready`.
